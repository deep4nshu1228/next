# =============================================================================
# Split 28-Week Dataset by Interaction Thresholds: 0-8, 8-16, 16-28 weeks
# =============================================================================

import pandas as pd
import numpy as np
import logging
import os

logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

# -------------------------
# 1) Calculate Interaction Weeks per Customer-SKU Pair
# -------------------------
df_calc = df.copy()
df_calc["interaction_flag"] = (df_calc["TOTAL_QUANTITY"] > 0).astype(int)

pair_weeks = (
    df_calc.groupby(["CUSTOMER_EXTERNAL_CODE", "SKU_ERP_CODE"])
    .agg(num_interaction_weeks=("interaction_flag", "sum"))
    .reset_index()
)

logging.info(f"Total customer-SKU pairs: {len(pair_weeks):,}")
logging.info(f"Total weeks in dataset: {df['WEEK_START_DATE'].nunique()}")
display(pair_weeks["num_interaction_weeks"].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))

# -------------------------
# 2) Define Three Threshold Groups
# -------------------------
def assign_threshold_group(num_weeks):
    """Assign to one of three groups based on interaction weeks"""
    if 0 <= num_weeks <= 8:
        return "0_to_8_weeks"
    elif 9 <= num_weeks <= 16:
        return "9_to_16_weeks"
    elif 17 <= num_weeks <= 28:
        return "17_to_28_weeks"
    else:
        return "out_of_range"  # Should not happen with 28-week data

pair_weeks["threshold_group"] = pair_weeks["num_interaction_weeks"].apply(assign_threshold_group)

# Summary of distribution
threshold_summary = (
    pair_weeks.groupby("threshold_group")
    .agg(
        num_pairs=("CUSTOMER_EXTERNAL_CODE", "count"),
        mean_weeks=("num_interaction_weeks", "mean"),
        median_weeks=("num_interaction_weeks", "median"),
        min_weeks=("num_interaction_weeks", "min"),
        max_weeks=("num_interaction_weeks", "max")
    )
    .reset_index()
)

logging.info("Threshold group distribution:")
display(threshold_summary)

# -------------------------
# 3) Merge Back to Full Dataset
# -------------------------
df_split = df.merge(
    pair_weeks[["CUSTOMER_EXTERNAL_CODE", "SKU_ERP_CODE", "threshold_group", "num_interaction_weeks"]],
    on=["CUSTOMER_EXTERNAL_CODE", "SKU_ERP_CODE"],
    how="left"
)

# -------------------------
# 4) Save Each Group to Separate File
# -------------------------
output_dir = "data_by_interaction_threshold"
os.makedirs(output_dir, exist_ok=True)

threshold_stats = []

for group_name in ["0_to_8_weeks", "9_to_16_weeks", "17_to_28_weeks"]:
    subset = df_split[df_split["threshold_group"] == group_name].copy()
    
    if len(subset) == 0:
        logging.warning(f"No data for {group_name}")
        continue
    
    # Drop metadata columns
    subset_clean = subset.drop(columns=["threshold_group", "num_interaction_weeks"], errors="ignore")
    
    # Save to parquet
    output_path = os.path.join(output_dir, f"data_{group_name}.parquet")
    subset_clean.to_parquet(output_path, index=False)
    
    # Collect stats
    stats = {
        "threshold_group": group_name,
        "num_rows": len(subset),
        "num_customers": subset["CUSTOMER_EXTERNAL_CODE"].nunique(),
        "num_skus": subset["SKU_ERP_CODE"].nunique(),
        "num_pairs": subset.groupby(["CUSTOMER_EXTERNAL_CODE", "SKU_ERP_CODE"]).ngroups,
        "total_qty": subset["TOTAL_QUANTITY"].sum(),
        "total_value": subset["TOTAL_DLP_VALUE"].sum(),
        "avg_weeks_per_pair": subset["num_interaction_weeks"].mean()
    }
    threshold_stats.append(stats)
    
    logging.info(f"✓ Saved {group_name}: {len(subset):,} rows | "
                 f"{stats['num_customers']:,} customers | "
                 f"{stats['num_skus']:,} SKUs | "
                 f"{stats['num_pairs']:,} pairs")

# -------------------------
# 5) Save Summary Statistics
# -------------------------
stats_df = pd.DataFrame(threshold_stats)

# Calculate percentages
stats_df["pct_of_total_rows"] = (stats_df["num_rows"] / stats_df["num_rows"].sum() * 100).round(2)
stats_df["pct_of_total_qty"] = (stats_df["total_qty"] / stats_df["total_qty"].sum() * 100).round(2)
stats_df["pct_of_total_value"] = (stats_df["total_value"] / stats_df["total_value"].sum() * 100).round(2)

logging.info("
=== Final Summary ===")
display(stats_df)

stats_df.to_csv(os.path.join(output_dir, "threshold_summary.csv"), index=False)
pair_weeks.to_csv(os.path.join(output_dir, "pair_interaction_weeks.csv"), index=False)

logging.info(f"
✓ All files saved to: {output_dir}/")
logging.info(f"  - data_0_to_8_weeks.parquet (low activity)")
logging.info(f"  - data_9_to_16_weeks.parquet (medium activity)")
logging.info(f"  - data_17_to_28_weeks.parquet (high activity)")
logging.info(f"  - threshold_summary.csv (statistics)")
logging.info(f"  - pair_interaction_weeks.csv (pair metadata)")
