# PURE SNOWPARK STORED PROCEDURE + IMPLICIT LIBRARY
# Configurable QUANTITY/VALUE | City CF | 6mo exclude | Top 20

from snowflake.snowpark import Session
from snowflake.snowpark.stored_procedure import StoredProcedureRegistration
from snowflake.snowpark.types import StringType, StructType, StructField, FloatType
import implicit  # pip install implicit
import numpy as np
import pandas as pd
from typing import Dict, List

# 1. CONFIG
RATING_TYPE = "QUANTITY"  # QUANTITY | VALUE | BOTH
ALPHA = 40  # Implicit confidence scaling
FACTORS = 20

# 2. SNOWPARK SESSION
connection_parameters = {
    "account": "<your_account>",
    "user": "<your_user>", 
    "password": "<your_password>",
    "warehouse": "<your_warehouse>",
    "database": "<your_database>",
    "schema": "<your_schema>"
}
session = Session.builder.configs(connection_parameters).create()

# 3. PREPARE DATA (Snowpark â†’ pandas for implicit)
recent_orders = session.table("your_orders_table").select(
    col("CUSTOMER_EXTERNAL_CODE").alias("customer_id"),
    col("SKU_ERP_CODE").alias("sku"),
    col("DEALER_CITY").alias("city"),
    col("WEEK_START_DATE"),
    col("TOTAL_QUANTITY"),
    col("TOTAL_DLP_VALUE")
).filter(col("WEEK_START_DATE") >= (current_date() - 180))

# Configurable rating
if RATING_TYPE == "QUANTITY":
    recent_orders = recent_orders.with_column("confidence", col("TOTAL_QUANTITY"))
elif RATING_TYPE == "VALUE":
    recent_orders = recent_orders.with_column("confidence", col("TOTAL_DLP_VALUE"))
else:
    recent_orders = recent_orders.with_column("confidence", col("TOTAL_QUANTITY") * col("TOTAL_DLP_VALUE"))

data_pd = recent_orders.filter(col("confidence") > 0).to_pandas()
print(f"Data loaded: {len(data_pd)} interactions | Rating: {RATING_TYPE}")

# 4. STORED PROCEDURE WITH IMPLICIT ALS (runs on Snowflake!)
def implicit_als_training(session: Session) -> str:
    """Snowpark SP: Train implicit ALS per city"""
    
    # Group by city
    cities = data_pd['city'].unique()
    results = {}
    
    for city in cities:
        city_data = data_pd[data_pd['city'] == city]
        if len(city_data) < 1000:  # Skip small cities
            continue
            
        # Create sparse matrix (customers Ã— skus)
        customers = city_data['customer_id'].astype('category').cat.codes
        skus = city_data['sku'].astype('category').cat.codes
        
        # Implicit confidence matrix
        sparse_matrix = implicit.coo_matrix((city_data['confidence'], (customers, skus)))
        sparse_matrix = sparse_matrix.tocsr()
        
        # Train AlternatingLeastSquares
        model = implicit.als.AlternatingLeastSquares(
            factors=FACTORS,
            alpha=ALPHA,
            iterations=15,
            regularization=0.01,
            use_gpu=False  # Snowflake CPU warehouse
        )
        model.fit(sparse_matrix)
        
        # Store model (joblib)
        import joblib
        joblib.dump(model, f"/tmp/{city}_als_model.pkl")
        results[city] = f"Trained {sparse_matrix.shape[0]} customers, {sparse_matrix.shape[1]} skus"
    
    return f"Trained {len(results)} cities: {results}"

# Register & RUN Stored Procedure
implicit_sp = StoredProcedureRegistration(
    session, 
    implicit_als_training,
    packages=['implicit', 'pandas', 'numpy', 'joblib', 'snowflake-snowpark-python'],
    return_type=StringType(),
    input_types=[]
)

print("ðŸš€ Training Implicit ALS...")
result = implicit_sp()
print(result)

# 5. GENERATE RECOMMENDATIONS STORED PROCEDURE
def generate_implicit_recs(session: Session, customer_id: str, city: str) -> str:
    """Get top 20 recs for customer"""
    import joblib
    
    model = joblib.load(f"/tmp/{city}_als_model.pkl")
    
    # Get customer/item indices
    city_data = data_pd[data_pd['city'] == city]
    customer_idx = city_data[city_data['customer_id'] == customer_id]['customer_id'].cat.codes.iloc[0]
    
    # Implicit ALS recommendations
    recs = model.recommend(customer_idx, city_data['sku'].cat.codes, N=50)
    
    # Map back + exclude recent
    recent_purchases = set(city_data[
        (city_data['customer_id'] == customer_id)
    ]['sku'].tolist())
    
    top_skus = []
    for sku_idx, score in recs:
        sku = city_data['sku'].cat.categories[sku_idx]
        if sku not in recent_purchases:
            top_skus.append((sku, float(score)))
            if len(top_skus) == 20:
                break
    
    # Save results
    recs_df = pd.DataFrame(top_skus, columns=['sku', 'score'])
    session.create_dataframe(recs_df).write.mode("overwrite") \
        .save_as_table(f"IMPLICIT_ALS_RECS_{customer_id.replace(' ', '_')}")
    
    return f"Generated {len(top_skus)} recs for {customer_id}"

# Usage
TEST_CUSTOMER = "CUST12345"
TEST_CITY = "Delhi"
rec_sp = StoredProcedureRegistration(
    session, lambda s: generate_implicit_recs(s, TEST_CUSTOMER, TEST_CITY),
    packages=['implicit', 'pandas', 'joblib']
)
print(rec_sp())

customer_recs = session.table(f"IMPLICIT_ALS_RECS_{TEST_CUSTOMER.replace(' ', '_')}")
customer_recs.order_by(col("score").desc()).show(20)

session.close()
print("âœ… IMPLICIT LIBRARY ALS COMPLETE!")
