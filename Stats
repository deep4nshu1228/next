# ONE-CELL WARRANTY VOLATILITY ANALYSIS

import pandas as pd
import numpy as np
import warnings
from IPython.display import display

warnings.filterwarnings("ignore")

# ----------------------------
# CONFIG
# ----------------------------
excel_path = "your_warranty.xlsx"   # change this to your file
out_path   = "warranty_volatility_report.xlsx"

# ----------------------------
# UTILS
# ----------------------------
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = (
        df.columns.astype(str)
        .str.strip()
        .str.lower()
        .str.replace(" ", "_")
        .str.replace("-", "_")
    )
    return df

def identify_cols(df: pd.DataFrame, candidates):
    for c in candidates:
        if c in df.columns:
            return c
    return None

def coefficient_of_variation(s: pd.Series):
    s = s.dropna()
    if len(s) < 2:
        return np.nan
    mu = s.mean()
    if mu == 0:
        return np.nan
    return float(s.std(ddof=1) / mu * 100.0)  # CV%

def rolling_std(s: pd.Series, window=3, min_periods=3):
    # 3-period rolling volatility by default
    return s.rolling(window=window, min_periods=min_periods).std(ddof=1)

def summarize_numeric(s: pd.Series):
    s = s.dropna()
    if s.empty:
        return dict(mean=np.nan, std=np.nan, cv=np.nan, min=np.nan, max=np.nan, count=0, rng=np.nan)
    return dict(
        mean=float(s.mean()),
        std=float(s.std(ddof=1)),
        cv=coefficient_of_variation(s),
        min=float(s.min()),
        max=float(s.max()),
        count=int(s.shape[0]),
        rng=float(s.max() - s.min()),
    )

# ----------------------------
# ANALYZERS
# ----------------------------
def analyze_overall(df: pd.DataFrame):
    df = normalize_columns(df).dropna(how="all").dropna(axis=1, how="all")
    time_col = identify_cols(df, ["month", "date", "period", "month_year"])

    # parse time if present
    if time_col and not np.issubdtype(df[time_col].dtype, np.number):
        try:
            df[time_col] = pd.to_datetime(df[time_col], errors="coerce")
        except Exception:
            pass

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    overall_summary = {}
    for col in numeric_cols:
        overall_summary[col] = summarize_numeric(df[col])
    overall_summary = pd.DataFrame(overall_summary).T
    overall_summary.index.name = "metric"

    rolling_summary = None
    if time_col is not None:
        df = df.sort_values(by=time_col)
        roll_dict = {}
        for col in numeric_cols:
            rs = rolling_std(df[col], window=3, min_periods=3)
            roll_dict[col] = dict(
                avg_rolling_std=float(rs.mean(skipna=True)) if rs.notna().any() else np.nan
            )
        rolling_summary = pd.DataFrame(roll_dict).T
        rolling_summary.index.name = "metric"

    return overall_summary, rolling_summary

def analyze_grouped(df: pd.DataFrame, group_key_candidates):
    df = normalize_columns(df).dropna(how="all").dropna(axis=1, how="all")
    group_col = identify_cols(df, group_key_candidates) or df.columns[0]

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if group_col in numeric_cols:
        numeric_cols.remove(group_col)

    rows = []
    for g, gdf in df.groupby(group_col, dropna=True):
        row = {group_col: g}
        for col in numeric_cols:
            stats = summarize_numeric(gdf[col])
            row[f"{col}_mean"] = stats["mean"]
            row[f"{col}_std"] = stats["std"]
            row[f"{col}_cv"] = stats["cv"]
            row[f"{col}_min"] = stats["min"]
            row[f"{col}_max"] = stats["max"]
            row[f"{col}_range"] = stats["rng"]
        rows.append(row)

    summary = pd.DataFrame(rows)

    # choose a primary metric CV for ranking
    primary_candidates = [
        "claim_rate", "cost_per_claim", "combined_metric",
        "claims", "total_claims", "cost", "total_cost", "vehicles"
    ]
    primary = None
    for base in primary_candidates:
        if f"{base}_cv" in summary.columns:
            primary = f"{base}_cv"
            break
    if primary is None:
        cv_cols = [c for c in summary.columns if c.endswith("_cv")]
        primary = cv_cols[0] if cv_cols else None

    ranking = None
    if primary:
        ranking = summary.sort_values(primary, ascending=False).reset_index(drop=True)

    return group_col, summary, ranking

# ----------------------------
# RUN
# ----------------------------
# Read all sheets into dict of DataFrames
sheets = pd.read_excel(excel_path, sheet_name=None)  # dict[str, DataFrame]
print(f"Loaded sheets: {list(sheets.keys())}")

results = {}

for name, df in sheets.items():
    name_l = name.lower()
    print(f"\n=== Analyzing sheet: {name} ===")

    if "overall" in name_l:
        overall_summary, overall_rolling = analyze_overall(df)
        print("Overall summary:")
        display(overall_summary)
        results[f"{name}_summary"] = overall_summary

        if overall_rolling is not None:
            print("Overall rolling volatility (avg rolling std over window=3):")
            display(overall_rolling)
            results[f"{name}_rolling"] = overall_rolling

    elif "family" in name_l:
        group_col, summary, ranking = analyze_grouped(df, ["family", "category", "segment", "class"])
        print(f"Family-wise summary (grouped by '{group_col}'):")
        display(summary)
        results[f"{name}_by_{group_col}"] = summary

        if ranking is not None:
            print("Family-wise volatility ranking (by CV):")
            display(ranking)
            results[f"{name}_ranking_by_cv"] = ranking

    elif "model" in name_l:
        group_col, summary, ranking = analyze_grouped(df, ["model", "product", "variant", "type"])
        print(f"Model-wise summary (grouped by '{group_col}'):")
        display(summary)
        results[f"{name}_by_{group_col}"] = summary

        if ranking is not None:
            print("Model-wise volatility ranking (by CV):")
            display(ranking)
            results[f"{name}_ranking_by_cv"] = ranking

    else:
        # fallback: generic grouped
        group_col, summary, ranking = analyze_grouped(df, ["model", "family"])
        print(f"Generic grouped summary (by '{group_col}'):")
        display(summary)
        results[f"{name}_by_{group_col}"] = summary

        if ranking is not None:
            print("Generic volatility ranking (by CV):")
            display(ranking)
            results[f"{name}_ranking_by_cv"] = ranking

# ----------------------------
# HIGH VOLATILITY ALERTS (CV > 30%)
# ----------------------------
alerts = []
for key, rdf in results.items():
    if isinstance(rdf, pd.DataFrame) and any(c.endswith("_cv") for c in rdf.columns):
        # try to infer group column (first non-numeric, non-_cv col)
        group_col_guess = None
        for c in rdf.columns:
            if not c.endswith("_cv") and not np.issubdtype(rdf[c].dtype, np.number):
                group_col_guess = c
                break

        for _, row in rdf.iterrows():
            for c in [x for x in rdf.columns if x.endswith("_cv")]:
                val = row.get(c, np.nan)
                if pd.notna(val) and val > 30:
                    alerts.append(dict(sheet=key, group=row.get(group_col_guess, "ALL"), metric=c, cv=val))

alerts_df = pd.DataFrame(alerts).sort_values("cv", ascending=False) if alerts else pd.DataFrame(columns=["sheet","group","metric","cv"])
print("\nHigh Volatility Alerts (CV > 30%):")
display(alerts_df)

# ----------------------------
# EXPORT TO EXCEL (optional)
# ----------------------------
with pd.ExcelWriter(out_path, engine="xlsxwriter") as writer:
    for name, df in results.items():
        if isinstance(df, pd.DataFrame):
            df.to_excel(writer, sheet_name=str(name)[:31])
    if not alerts_df.empty:
        alerts_df.to_excel(writer, sheet_name="high_vol_alerts", index=False)

print(f"\nReport written to: {out_path}")
